<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Justin Collins' Blugh]]></title>
  <link href="http://presidentbeef.github.com/atom.xml" rel="self"/>
  <link href="http://presidentbeef.github.com/"/>
  <updated>2019-08-04T00:17:55-07:00</updated>
  <id>http://presidentbeef.github.com/</id>
  <author>
    <name><![CDATA[Justin Collins]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Reviving an HP 660LX in 2019]]></title>
    <link href="http://presidentbeef.github.com/blog/2019/08/04/reviving-an-hp660lx-in-2019/"/>
    <updated>2019-08-04T09:52:00-07:00</updated>
    <id>http://presidentbeef.github.com/blog/2019/08/04/reviving-an-hp660lx-in-2019</id>
    <content type="html"><![CDATA[<p>It started off as a joke&#8230;</p>

<blockquote class="twitter-tweet" data-dnt="true" data-link-color="#E81C4F"><p lang="en" dir="ltr">Just setting up my burner machine for <a href="https://twitter.com/defcon?ref_src=twsrc%5Etfw">@defcon</a> <a href="https://t.co/Dz9pjCBTCo">pic.twitter.com/Dz9pjCBTCo</a></p>&mdash; Justin Collins (@presidentbeef) <a href="https://twitter.com/presidentbeef/status/1144761345847336960?ref_src=twsrc%5Etfw">June 29, 2019</a></blockquote>


<p> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>

<p>I had spent some time <em>several years ago</em> trying to get Linux running on this machine via the (defunct) JLime project,
so I had some of the pieces available to actually get this little &#8220;pocket computer&#8221; going again - mainly
compatible CompactFlash cards and an external card reader.
But I was mostly joking.</p>

<p>Then I starting thinking how funny it would be to actually sit in a talk and take notes at <a href="https://defcon.org/">DEF CON</a> on it&#8230;</p>

<h3>Battery Power</h3>

<p>The reason I was mostly joking is because the batteries in the 660LX were not working at all.
So, what was I going to do? Plug it into the wall? That&#8217;s just sad, not funny.</p>

<p>I started looking around online for replacement batteries for this machine from 1998.
Despite visiting several rather shady websites, for some reason I was unable to find anyone selling twenty-year-old
laptop batteries.
Some sites claimed to offer a replacement, but from the pictures it was clear they would not work.
The only real possibilities I found were complete sets - a 660LX, manual, cables, etc.
I already had a 660LX, acquired for free, so I really didn&#8217;t want to spend $100+ on another one!
Also, kind of ruins the joke to do so.</p>

<p><em>(Side note: the 660LX has a button battery for backup power. Searching for &#8220;HP 660LX battery&#8221; will return sites trying to sell
you a little CR2032 battery.)</em></p>

<p>Now, I will admit my mental model of a laptop battery was a block of chemical goop inside of some plastic wrap with some wires coming out of it.
After ungracefully disassembling the 660LX battery, I found inside it was just two smaller batteries?!</p>

<p><a href="http://presidentbeef.github.com/images/blog/hp_660lx/hp660lx_battery_open.jpg"><img src="http://presidentbeef.github.com/images/blog/hp_660lx/hp660lx_battery_open.jpg" alt="Open battery pack of HP 660LX" /></a></p>

<p>The batteries said &#8220;US18650S SONY ENERGYTEC&#8221; on them.</p>

<p><a href="http://presidentbeef.github.com/images/blog/hp_660lx/hp_660lx_old_batteries.jpg"><img src="http://presidentbeef.github.com/images/blog/hp_660lx/hp_660lx_old_batteries.jpg" alt="Sony 18650S Batteries" /></a></p>

<p>While I didn&#8217;t find those exact batteries, some investigation showed the 18650 battery in general is extremely common.</p>

<p>There are two kinds of 18650 - one with &#8220;caps&#8221; (that little nub on the top) and one without.
It seems the ones with caps are safer, as they have an internal circuit to keep them from blowing up.
However, as you can see above, I needed the kind without caps. Presumably the little circuit board
regulates charging the batteries.</p>

<p>The Internet suggested sticking to &#8220;brand name&#8221; batteries, but weirdly Amazon does not carry any of those.
I took a chance on a pack of batteries which reviewers suggested looked like &#8220;genuine&#8221; Samsung batteries.</p>

<p><a href="http://presidentbeef.github.com/images/blog/hp_660lx/samsung_18650-30Q_batteries.jpg"><img src="http://presidentbeef.github.com/images/blog/hp_660lx/samsung_18650-30Q_batteries.jpg" alt="Samsung 18650 batteries" /></a></p>

<p>I carefully ripped the old batteries out. The leads from the batteries to the little circuit board were
actually soldered to the batteries, so I pried them off with a screwdriver. Probably not a great idea
unless they are really, truly dead.</p>

<p>With some effort, I shoved the new batteries back in the case and sandwiched the wires back in as well.
I didn&#8217;t bother actually attaching/gluing/soldering anything.</p>

<p>I did, however, scare myself when I generated a terrifying little electric arc as I
tried to use a screwdriver to squeeze everything back into the battery case.</p>

<p><a href="http://presidentbeef.github.com/images/blog/hp_660lx/hp660lx_batteries_replaced.jpg"><img src="http://presidentbeef.github.com/images/blog/hp_660lx/hp660lx_batteries_replaced.jpg" alt="HP 660LX batteries replaced" /></a></p>

<p>I may have damaged the case just a tiny bit when I gently pried it open,
contributing to it looking a slightly sketchy when I tried to close it back up.</p>

<p><a href="http://presidentbeef.github.com/images/blog/hp_660lx/hp660lx_battery_together.jpg"><img src="http://presidentbeef.github.com/images/blog/hp_660lx/hp660lx_battery_together.jpg" alt="HP 660LX battery put back together" /></a></p>

<p>But, who cares how it looks&#8230;does it work??</p>

<p><a href="http://presidentbeef.github.com/images/blog/hp_660lx/hp660lx_running_on_new_batteries.jpg"><img src="http://presidentbeef.github.com/images/blog/hp_660lx/hp660lx_running_on_new_batteries.jpg" alt="HP 660LX running on battery power" /></a></p>

<p><strong>YES!</strong></p>

<p>Hahahaha now I can walk around using my relic with no wires!</p>

<h3>Software Updates</h3>

<p>Nowadays, a device that can&#8217;t connect to anything does not seem like much fun.</p>

<p>Of course I wanted to hook this Windows CE 2.0 machine up to the Internet!</p>

<p>The HP 660LX has a &#8220;PC CARD&#8221; expansion slot where you can slap in an Ethernet or wireless card,
but of course it is ancient and you have to be careful about compatibility.</p>

<p>Enter <a href="https://www.hpcfactor.com/">HPC: Factor</a>! This is a website/forum full of useful information.
For £10 you can get access to a ton of file downloads (software, drivers, updates) for a year.
Totally worth it.</p>

<p>One thing I learned quickly is that you need the service pack for Windows CE 2.0 and the Network Service Pack
in order to have a chance at getting a wireless card to work.</p>

<p>At this point, I had been transferring files to the 660LX via a compact flash card (which, at 8GB, probably blew the little machine&#8217;s <em>mind</em>).
However, most software for Windows CE requires installation via ActiveSync.</p>

<p><a href="http://presidentbeef.github.com/images/blog/hp_660lx/kingston_cf_8gb_card.jpg"><img src="http://presidentbeef.github.com/images/blog/hp_660lx/kingston_cf_8gb_card.jpg" alt="Kingston CompactFlash card" /></a></p>

<p>What is ActiveSync? Well, originally these &#8220;pocket computers&#8221; weren&#8217;t meant to be tiny laptops.
They were more like little helpers you use while you are away from your main machine, then you sync up
files, calendars, email, etc. when you went back to your desk.</p>

<p>ActiveSync was the software used to sync between a pocket computer and your main machine.</p>

<p>Now, for Windows CE 2.0, the recommended version of ActiveSync is 3.8. The very <em>newest</em> operating system
supported by ActiveSync 3.8 is Windows XP.</p>

<p>By pure luck, I had an old Windows XP laptop and I was able to install ActiveSync!</p>

<p><strong>BUT</strong>&#8230; you need a special serial cable to hook up the 660LX.
At first I poked around eBay, but no luck. Yet, in the back of my mind,
I was <em>pretty</em> sure I still had that cable somewhere. I searched all around my office and
dug through my big box of (mostly useless) cables,
but still no luck.</p>

<p>Just when I gave up (of course) I found it!! Yay!!</p>

<p><strong>BUT</strong>&#8230; turns out I don&#8217;t have a serial port on my Windows XP laptop.</p>

<p>I thought about trying a Windows XP virtual machine on my main Linux box, but it doesn&#8217;t have a serial port, either!
None of my machines had an infrared port, either.</p>

<p>After first buying the wrong cable on Amazon, I got an RS-232 to USB adapter and a tiny, tiny CD with drivers.
Luckily, the laptop has a CD drive, so I was able to actually install the proper drivers.</p>

<p><a href="http://presidentbeef.github.com/images/blog/hp_660lx/usb_to_serial_cable.jpg"><img src="http://presidentbeef.github.com/images/blog/hp_660lx/usb_to_serial_cable.jpg" alt="USB to serial cable" /></a></p>

<p>After an uncomfortable amount of configuration twiddling&#8230; they connected!!</p>

<p><a href="http://presidentbeef.github.com/images/blog/hp_660lx/active_sync_connected.jpg"><img src="http://presidentbeef.github.com/images/blog/hp_660lx/active_sync_connected.jpg" alt="ActiveSync is connected" /></a></p>

<p>I was then able to install Windows CE 2.0 SP1 and the CE Network Service Pack.</p>

<p><a href="http://presidentbeef.github.com/images/blog/hp_660lx/install_ce_sp1.jpg"><img src="http://presidentbeef.github.com/images/blog/hp_660lx/install_ce_sp1.jpg" alt="Installing Windows CE SP1" /></a></p>

<h3>Networking</h3>

<p>One of my criteria for this project was to <em>not spend much money on a joke</em>.</p>

<p>After spending some time looking around, I bought a $20 wireless adapter off of eBay.
$20 was really right at the limit of my per-item budget.</p>

<p>In the meantime, though, I found out there was another way to access the Internet.</p>

<p>Turns out you can &#8220;share&#8221; the networking connection on the main machine with the 660LX
over the serial cable, via ActiveSync.</p>

<p>The only weird bit is that you need to run a proxy server on the main machine to route
the connection to the Internet.</p>

<p>In the modern world, that is not a problem. In the land of Windows XP, however, I was not sure I would be able to get something working.
I found <a href="https://www.youngzsoft.net/ccproxy/windows-proxy-server.htm">CCProxy</a>, which did work, despite its awful and confusing interface.</p>

<p>Configured the proxy for &#8220;The Internet&#8221; on the 660LX and&#8230;</p>

<p><a href="http://presidentbeef.github.com/images/blog/hp_660lx/hp660lx_accessing_google.jpg"><img src="http://presidentbeef.github.com/images/blog/hp_660lx/hp660lx_accessing_google.jpg" alt="Accessing Google via Pocket Explorer" /></a></p>

<p>Wow! The Internet!</p>

<p>Sadly&#8230; or not so sadly&#8230; the world has moved to HTTPS and to stronger protocols than what
lowly Pocket Explorer supports. Thus, most of the web is entirely inaccessible on the device.</p>

<p><a href="http://presidentbeef.github.com/images/blog/hp_660lx/hp660lx_failure_to_access_github.jpg"><img src="http://presidentbeef.github.com/images/blog/hp_660lx/hp660lx_failure_to_access_github.jpg" alt="Failure to access sites over HTTPS" /></a></p>

<p>As a result, when the eBay seller canceled my order for the wireless adapter, I figured &#8220;meh&#8221;.
Even if you can get WiFi working (which would likely require connecting to a totally unsecured network),
there&#8217;s not much of the web that one can even visit.</p>

<p>Yes, it would be possible to use an SSL stripper, etc., but I didn&#8217;t want to go through the hassle of setting
that up on Windows XP.</p>

<h3>Wrapping Up</h3>

<p><a href="http://presidentbeef.github.com/images/blog/hp_660lx/the_whole_setup.jpg"><img src="http://presidentbeef.github.com/images/blog/hp_660lx/the_whole_setup.jpg" alt="The whole setup" /></a></p>

<p>This turned into more of a narrative than a how-to guide.
Maybe I&#8217;ll do another write-up with the details.
In the meantime, I can try to answer questions about specifics.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Finding Ruby Performance Hotspots via Allocation Stats]]></title>
    <link href="http://presidentbeef.github.com/blog/2018/11/28/finding-ruby-performance-hotspots-via-allocation-stats/"/>
    <updated>2018-11-28T11:45:00-08:00</updated>
    <id>http://presidentbeef.github.com/blog/2018/11/28/finding-ruby-performance-hotspots-via-allocation-stats</id>
    <content type="html"><![CDATA[<p><a href="https://github.com/seattlerb/ruby_parser/">RubyParser</a> is a library written by <a href="http://www.zenspider.com/">Ryan Davis</a> for parsing Ruby code and producing an abstract syntax tree. It is used by <a href="https://brakemanscanner.org/">Brakeman</a> and several other static analysis gems.</p>

<p>Recently I was poking around to see if there was any low-hanging fruit for performance improvements.
At first, I was interested in the generated parsers. Racc outputs some <em>crazy</em> arrays of state machine changes.
Instead of generating arrays of integers, it outputs arrays of strings, then splits those strings into integers which it loads into the final array.
I thought for sure skipping this and starting with the final array of integers would be faster, but&#8230;somehow it wasn&#8217;t.</p>

<p>I moved on to thinking about <a href="https://wyeworks.com/blog/2015/12/1/immutable-strings-in-ruby-2-dot-3">frozen string literals</a>, which led me to checking String allocations.</p>

<h3>Measuring String Allocations</h3>

<p>I found the <a href="https://github.com/srawlins/allocation_stats">allocation_stats</a> gem very useful for this.</p>

<p>I set up a test like this to read in a file and parse it:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="nb">require</span> <span class="s1">&#39;ruby_parser&#39;</span>
</span><span class='line'><span class="nb">require</span> <span class="s1">&#39;allocation_stats&#39;</span>
</span><span class='line'>
</span><span class='line'><span class="n">f</span> <span class="o">=</span> <span class="no">File</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="no">ARGV</span><span class="o">[</span><span class="mi">0</span><span class="o">]</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="n">rp</span> <span class="o">=</span> <span class="no">RubyParser</span><span class="o">.</span><span class="n">new</span>
</span><span class='line'>
</span><span class='line'><span class="n">stats</span> <span class="o">=</span> <span class="no">AllocationStats</span><span class="o">.</span><span class="n">trace</span> <span class="k">do</span>
</span><span class='line'>  <span class="n">rp</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="no">ARGV</span><span class="o">[</span><span class="mi">0</span><span class="o">]</span><span class="p">,</span> <span class="mi">40</span><span class="p">)</span>
</span><span class='line'><span class="k">end</span>
</span><span class='line'>
</span><span class='line'><span class="nb">puts</span> <span class="n">stats</span><span class="o">.</span><span class="n">allocations</span><span class="p">(</span><span class="n">alias_paths</span><span class="p">:</span> <span class="kp">true</span><span class="p">)</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="ss">class</span><span class="p">:</span> <span class="nb">String</span><span class="p">)</span><span class="o">.</span><span class="n">group_by</span><span class="p">(</span><span class="ss">:sourcefile</span><span class="p">,</span> <span class="ss">:sourceline</span><span class="p">)</span><span class="o">.</span><span class="n">sort_by_count</span><span class="o">.</span><span class="n">to_text</span>
</span></code></pre></td></tr></table></div></figure>


<p>This outputs a report like this (truncated here):</p>

<pre><code>                    sourcefile                      sourceline  count
--------------------------------------------------  ----------  -----
&lt;GEM:ruby_parser-3.11.0&gt;/lib/ruby_parser.rb                 20  70686
&lt;GEM:ruby_parser-3.11.0&gt;/lib/ruby_parser_extras.rb        1361  58154
&lt;GEM:ruby_parser-3.11.0&gt;/lib/ruby_parser_extras.rb        1362  54672
&lt;GEM:ruby_parser-3.11.0&gt;/lib/ruby_lexer.rb                 373  19019
&lt;GEM:ruby_parser-3.11.0&gt;/lib/ruby_lexer.rb                 770  12005
&lt;GEM:ruby_parser-3.11.0&gt;/lib/ruby_lexer.rex.rb             109   8252
&lt;GEM:ruby_parser-3.11.0&gt;/lib/ruby_parser_extras.rb        1015   6818
</code></pre>

<p>Right away, these look like some juicy targets.</p>

<h3>Version Creation</h3>

<p>Let&#8217;s take a look at the first one:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="k">class</span> <span class="nc">Parser</span> <span class="o">&lt;</span> <span class="ss">Racc</span><span class="p">:</span><span class="ss">:Parser</span>
</span><span class='line'>  <span class="kp">include</span> <span class="no">RubyParserStuff</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">def</span> <span class="nc">self</span><span class="o">.</span><span class="nf">inherited</span> <span class="n">x</span>
</span><span class='line'>    <span class="ss">RubyParser</span><span class="p">:</span><span class="ss">:VERSIONS</span> <span class="o">&lt;&lt;</span> <span class="n">x</span>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">def</span> <span class="nc">self</span><span class="o">.</span><span class="nf">version</span>
</span><span class='line'>    <span class="no">Parser</span> <span class="o">&gt;</span> <span class="nb">self</span> <span class="ow">and</span> <span class="nb">self</span><span class="o">.</span><span class="n">name</span><span class="o">[</span><span class="sr">/(?:V|Ruby)(\d+)/</span><span class="p">,</span> <span class="mi">1</span><span class="o">].</span><span class="n">to_i</span>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure>


<p>On line 8 you can see the <code>Parser.version</code> method. RubyParser is actually not just one parser, but multiple parsers for different versions of Ruby.
So there is a <code>RubyParser</code> class but also <code>Ruby18Parser</code>, <code>Ruby19Parser</code>, etc. <em>and</em> <code>RubyParser::V18</code>, <code>RubyParser::V19</code>, etc.
To figure out the version of the current class, the code above grabs the version from the class name itself.</p>

<p>The problem is this code is called <em>a lot</em> (70k+ in the example above) to make version-specific decisions during the lexing phase.
This is <a href="https://github.com/presidentbeef/ruby_parser/commit/7274aa6df023981fc3c375a9d22bcde781f2cc3f">fairly easy to fix</a>.</p>

<p>In my testing, this <strong>reduced string allocations by ~25% and parse time by 5-10%.</strong>
One thing I have noticed - and you may also find if you go chasing object allocations in Ruby programs - is that reducing allocations doesn&#8217;t necessarily help with peak memory use or run time.
It seems the Ruby VM has gotten pretty good at allocating and garbage collecting objects efficiently.</p>

<h3>Debug Code</h3>

<p>Let&#8217;s take a look at the next two large number of String allocations:</p>

<pre><code>                    sourcefile                      sourceline  count
--------------------------------------------------  ----------  -----
&lt;GEM:ruby_parser-3.11.0&gt;/lib/ruby_parser_extras.rb        1361  58154
&lt;GEM:ruby_parser-3.11.0&gt;/lib/ruby_parser_extras.rb        1362  54672
</code></pre>

<p>Interesting: just two lines apart, with over 100k allocations between them.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="k">def</span> <span class="nf">push</span> <span class="n">val</span>
</span><span class='line'>  <span class="vi">@stack</span><span class="o">.</span><span class="n">push</span> <span class="n">val</span>
</span><span class='line'>  <span class="n">c</span> <span class="o">=</span> <span class="nb">caller</span><span class="o">.</span><span class="n">first</span>
</span><span class='line'>  <span class="n">c</span> <span class="o">=</span> <span class="nb">caller</span><span class="o">[</span><span class="mi">1</span><span class="o">]</span> <span class="k">if</span> <span class="n">c</span> <span class="o">=~</span> <span class="sr">/expr_result/</span>
</span><span class='line'>  <span class="nb">warn</span> <span class="s2">&quot;</span><span class="si">#{</span><span class="nb">name</span><span class="si">}</span><span class="s2">_stack(push): </span><span class="si">#{</span><span class="n">val</span><span class="si">}</span><span class="s2"> at line </span><span class="si">#{</span><span class="n">c</span><span class="o">.</span><span class="n">clean_caller</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">if</span> <span class="n">debug</span>
</span><span class='line'>  <span class="kp">nil</span>
</span><span class='line'><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure>


<p>The two lines of interest are 3 and 4 - the assignments to the local variable <code>c</code>, which pull information from <code>caller</code>.
<code>caller</code> is a fairly expensive method, since it needs to generate a stack trace for the current method call.</p>

<p>Upon a closer look, it&#8217;s clear the <code>c</code> variable is only used in the message on the following line, and that message is only used if the <code>debug</code> flag is set.
This means we can wrap all that code in a condition, like this:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="k">def</span> <span class="nf">push</span> <span class="n">val</span>
</span><span class='line'>  <span class="vi">@stack</span><span class="o">.</span><span class="n">push</span> <span class="n">val</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">if</span> <span class="n">debug</span>
</span><span class='line'>    <span class="n">c</span> <span class="o">=</span> <span class="nb">caller</span><span class="o">.</span><span class="n">first</span>
</span><span class='line'>    <span class="n">c</span> <span class="o">=</span> <span class="nb">caller</span><span class="o">[</span><span class="mi">1</span><span class="o">]</span> <span class="k">if</span> <span class="n">c</span> <span class="o">=~</span> <span class="sr">/expr_result/</span>
</span><span class='line'>    <span class="nb">warn</span> <span class="s2">&quot;</span><span class="si">#{</span><span class="nb">name</span><span class="si">}</span><span class="s2">_stack(push): </span><span class="si">#{</span><span class="n">val</span><span class="si">}</span><span class="s2"> at line </span><span class="si">#{</span><span class="n">c</span><span class="o">.</span><span class="n">clean_caller</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>  <span class="kp">nil</span>
</span><span class='line'><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure>


<p>This change <strong>saves 38-50% on string allocations and 20-26% on parse time.</strong></p>

<h3>Reading Lines</h3>

<p>Skipping down a few unavoidable string allocations, there&#8217;s this one:</p>

<pre><code>                    sourcefile                      sourceline  count
--------------------------------------------------  ----------  -----
&lt;GEM:ruby_parser-3.11.0&gt;/lib/ruby_parser_extras.rb        1015   6818
</code></pre>

<p>Here&#8217;s the code:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="n">header</span> <span class="o">=</span> <span class="n">str</span><span class="o">.</span><span class="n">lines</span><span class="o">.</span><span class="n">first</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>RubyParser checks the first couple lines of a file for any comments setting the encoding for the file. The trouble is that calling <code>String#lines</code> will split the entire string up when we only need the first two lines.</p>

<p>Grabbing only the first two lines ends up being pretty trivial thanks to Ruby&#8217;s standard approach of returning enumerators for enumeration methods if a block is not supplied:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="n">header</span> <span class="o">=</span> <span class="n">str</span><span class="o">.</span><span class="n">each_line</span><span class="o">.</span><span class="n">first</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p><code>String#each_line</code> will lazily return the lines from the string, so it only does the work needed.</p>

<p>Sadly, this didn&#8217;t do much for overall string allocations and parse time since this method is only called once, but I think it&#8217;s a clear improvement to only grab the two lines needed.</p>

<h3>Freezing Strings</h3>

<p>Finally, back to the original idea. By the time I made it back to freezing string literals, I was feeling pretty lazy, so I just threw the frozen string header on <a href="https://github.com/seattlerb/ruby_parser/blob/dd2adeca68471a2de7a8d541fb145972f3e3494f/lib/ruby_lexer.rb"><code>ruby_lexer.rb</code></a>:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="c1"># frozen_string_literal: true</span>
</span></code></pre></td></tr></table></div></figure>


<p>Running the tests showed only one method where frozen string literals did not work, so these strings needed to be <code>dup</code>ed.</p>

<p>String allocations were reduced by 24-30%, but with almost no parse time change. Probably because these were tiny, tiny strings.</p>

<h3>Final Metrics</h3>

<p>With these four changes, <strong>string allocations were reduced by 75-83% and parse time was reduced by 30-37%.</strong> The test suite for RubyParser ran 33% faster on my machine.</p>

<p>I did not see a huge decrease in peak memory use. Maybe 3%. My guess is this is because the String representation in Ruby is fairly well-optimized already (e.g. copy-on-write).</p>

<p>For Brakeman, parsing is a decent part of the run time (30-60% even), so a faster RubyParser definitely makes Brakeman scans faster. From a few test scans, I saw as much as a 30% improvement in total scan time.</p>

<h3>Final Changes</h3>

<p>The final version of the changes applied by Ryan are in <a href="https://github.com/seattlerb/ruby_parser/commit/358e5a058e1eca75c6d6ab075ae31c2cc44827a5">this commit</a>.</p>

<p>I expect these improvements will be in the next RubyParser and Brakeman releases.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Price Transparency with Brakeman Pro]]></title>
    <link href="http://presidentbeef.github.com/blog/2017/12/21/price-transparency-with-brakeman-pro/"/>
    <updated>2017-12-21T19:39:00-08:00</updated>
    <id>http://presidentbeef.github.com/blog/2017/12/21/price-transparency-with-brakeman-pro</id>
    <content type="html"><![CDATA[<p>Pricing in the static analysis security tool (SAST) world is difficult. Do you charge per project? Per repository? Per line of code? Per language? Per user? What defines a &#8220;user&#8221;?
None of these approaches are very satisfying, because no single approach will cover all types of customers.</p>

<p>Instead, companies come up with per-customer pricing. Meaning they will look at a potential customer&#8217;s needs and size, and then come up with a number they think the customer might be willing to pay.</p>

<p>Then the negotation dance begins, where the customer attempts to talk the seller down 20-50% from the initial quote (which was kind of made up anyway).</p>

<p>To me, that&#8217;s stressful, time-consuming, and a little shady.</p>

<p>Personally, I do not want to deal with salespeople (and their relentless follow up emails/calls) just to get a rough idea of what a product will cost.</p>

<p>With Brakeman Pro, I wanted to be upfront and honest with customers. That&#8217;s why, as far as I know, we are the only commercial SAST with <a href="https://brakemanpro.com/purchase/pricing">publicly-available pricing</a>.</p>

<p>Want to purchase a license? You can buy with a credit card on the website and you never have to talk to anyone! That is the kind of interaction I like to have with a company - not &#8220;request a quote&#8221; or &#8220;contact us for pricing&#8221;.</p>

<p>Does that mean we make less money than if we had hidden price lists and made up numbers based on what we think a customer would pay? Almost certainly. Our customers range from companies making billions per year to individual users. It would be &#8220;smarter&#8221; to have the large companies pay more.</p>

<p>But the &#8220;mission&#8221; of the company is not to maximize profit. It is to fund development of a security product that will <em>help make the world a little safer</em>.</p>

<p>That is why it has been more important to me that we focus on number of customers, rather than overall revenue.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Challenges When Building Commercial Versions of Open Source]]></title>
    <link href="http://presidentbeef.github.com/blog/2017/03/08/challenges-when-building-commercial-versions-of-oss/"/>
    <updated>2017-03-08T21:53:00-08:00</updated>
    <id>http://presidentbeef.github.com/blog/2017/03/08/challenges-when-building-commercial-versions-of-oss</id>
    <content type="html"><![CDATA[<p>It has been roughly three years since the ball began rolling on <a href="https://brakemanpro.com/">Brakeman Pro</a> (the commercial version of the <a href="http://brakemanscanner.org/">Brakeman</a> security tool for Ruby on Rails), and it has been a little over a year since Brakeman Pro actually <a href="https://brakemanpro.com/blog/announcement/2015/11/18/brakeman-pro-is-available">went on sale</a>. I have learned a ton in that time (and I am still having lessons beaten into me). There have been a ton of challenges going from an OSS project that was never meant to be a paid product to one people are actually buying. Here are just a couple I have much time thinking about:</p>

<h2>The &#8220;Free&#8221; Version</h2>

<p>Clearly, what makes building a commercial product on top of an OSS project different from just selling some software is the existing OSS project itself.</p>

<p>With an OSS project, there is an opportunity to acquire a large number of people testing the software in many different environments. For a static analysis tool like Brakeman, testing on a wide variety of codebases is incredibly valuable. OSS with easy bug reporting and contributing (e.g. a GitHub repo) is not only very likely to receive bug reports and patches, but also suggestions for features and improvements. Brakeman does not receive a large number of code contributions, but bug reports and suggestions for new rules have driven a large chunk of Brakeman’s development.</p>

<p>Being free and open source also makes it easier to advertise your project. People are more willing to promote free software and you can share it around social media with little fear of backlash. Not to mention it is vastly easier to give  conference talks about open source tools!</p>

<p>Personally, I will forever be grateful to the OSS community. Being the main author of widely-used (within a small niche) software has propelled most of my career, led to me speaking all over the world, and has brought me acquaintances and friends I would not have otherwise. I am very glad Brakeman is open source and I would never want to change that.</p>

<p>However, the existence of a &#8220;free&#8221; version, especially a successful one, has a serious drawback for a business. In particular, <strong>the &#8220;paid&#8221; version must now not only justify its utility, but also the <em>incremental</em> advantage over the free version.</strong> It has become abundantly clear the biggest competitor to Brakeman Pro is Brakeman OSS!</p>

<p>The number one question I receive regarding Brakeman Pro is &#8220;What is the difference between Pro and the open source version?&#8221; Among other things, one very simple, easy-to-explain difference is the existence of a <a href="https://brakemanpro.com/features#dt">GUI</a>. However, most people want to know if it will &#8220;find more things.&#8221; This leads to considerable hedging from me because Pro probably will find <em>different</em> vulnerabilities while also reducing <em>some</em> false positives - the net outcome of which may be more or fewer overall warnings. Explaining why Pro may report different vulnerabilities quickly gets me lost in fine details of how the two tools work - at which point people&#8217;s eyes tend to glaze over.</p>

<p>Trying to quantify the differences between the OSS and Pro versions is a losing battle for me. Potential customers try to add up all these little details and see if it comes out to enough of a difference to begin paying for software they are used to having for free. But, as a technical person, papering over the differences with hyperbolic qualitative statements can seem dishonest. I have yet to arrive at a good solution for this problem.</p>

<h2>Existing User Base</h2>

<p>With a well-established OSS project comes another big advantage: the existing user base. These users already like the project and have found it useful! In a way, they have validated a market exists for the product. In the case of Brakeman, I have also felt a tremendous amount of goodwill from the community (for which, again, I am incredibly thankful).</p>

<p>These users are going to be the <em>very first</em> people in line to try the commercial product.* They will already be familiar with the OSS version - therefore communicating and justifying the <em>additional</em> value of the commercial version will be critical. The good news is they already know what the product does and have found it valuable. In some cases (but not very many, I’ve found) they may even purchase the product just to support the OSS version. In most cases, though, people need to justify why they are spending budget on this particular software instead of using the free version.</p>

<p><strong>If you are like me, you may also find this existing user base to be a source of stress.</strong> Marketing to OSS users often feels scummy, but it also makes no sense not to promote the commercial tool to the people already using the free version! For quite a while I did not want to take advantage of the existing audience at all. I have only made very small steps in that direction, preceded by a lot of thought. The last thing I want to do is alienate the community or burn any of the goodwill Brakeman has.</p>

<p>One way to push customers towards the commercial version is to make the OSS version obviously <em>worse</em>. But while it would make selling the commercial version easier, not working on or supporting the OSS version is unthinkable. Even the appearance of doing so could turn a community against you. When your potential customers are mostly developers the support of the developer community has extreme value. Besides the business aspect, I personally would have a hard time dealing with loss of the community when the community has done so much for me.</p>

<p>That leaves making the commercial version <em>so much better</em> than the OSS version the additional value is ridiculously obvious and people happily pay for it. Sadly (gladly?), many people have let me know &#8220;the free version of Brakeman is really good and already does all I need.&#8221; Making the Pro version <em>extra awesome</em> without hurting the OSS version is an ongoing struggle which I continue to hope will resolve itself over time as we continue to improve Pro.</p>

<p>Like many things, the existing user base for an OSS project has both advantages and disadvantages which need to be considered and kept in mind if one is going to turn the project into a commercial product.</p>

<h2>As a Security Tool&#8230;</h2>

<p>This probably does not apply to very many projects, but as a security tool Brakeman has additional issues related to those above. With every feature that might be exclusive to Pro, I must consider - <strong>&#8220;Am I making the world <em>less safe</em> by not adding this feature to the OSS version?&#8221;</strong> The answers to this question likely lead me to make terrible business decisions. In the end I can live without Brakeman Pro being a successful business, but consciously compromising my integrity and potentially the security of applications is not something I could personally handle.</p>

<p>As a result, the features that tend to go into Pro but not the OSS version are noisier, slower, or focused on ease of use and not actual vulnerability discovery. I believe more false positives (but potentially more true positives) are acceptable in the Pro version because we make it easy to triage and ignore them. Slower features are also much more acceptable in the Pro version - the OSS version needs to be fast and lean. (Sometimes these features also end up in OSS, just off by default. &#8220;Off by default&#8221; means they might as well not exist for most users.)</p>

<h2>Conclusions</h2>

<p>If you are considering taking an open source project and building a commercial tool on top of it, I hope this little post has given you some (perhaps less obvious?) issues to ponder. For Brakeman users, I hope this explains a little bit of the thinking I have done while trying to balance between OSS and Pro.</p>

<p>Note that this blog post is actually an example of the first two issues above: I had to tell you about the &#8220;free&#8221; version to talk about the Pro version and at the same time you probably feel like this is a bit of an advertisement for the Pro version!</p>

<p>(I think I have to plug my product here now? <a href="https://brakemanpro.com/">Brakeman Pro is a static analysis security tool for Ruby on Rails applications</a>. <a href="https://brakemanpro.com/purchase/pricing">Try it out for free</a>.)</p>

<hr />

<p>* <em>One of the early mistakes I made with Brakeman Pro was not realizing who the first customers would be. I thought the people most willing to <em>buy</em> a tool would be security auditors, and so the tool and pricing were targeted at <em>security professionals</em>. Unfortunately, the much larger market and initial user base for Brakeman are developers. Brakeman Pro should have made developers our top priority from the beginning just like Brakeman OSS does.</em></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Bundling Dependencies inside Ruby Gems]]></title>
    <link href="http://presidentbeef.github.com/blog/2016/08/09/bundling-gem-dependencies-inside-ruby-gems/"/>
    <updated>2016-08-09T08:53:00-07:00</updated>
    <id>http://presidentbeef.github.com/blog/2016/08/09/bundling-gem-dependencies-inside-ruby-gems</id>
    <content type="html"><![CDATA[<h3>Backstory</h3>

<p>I recently decided to distribute the <a href="http://brakemanscanner.org/">Brakeman</a> gem with all its dependencies included.
This was the culmination of a lot of frustration with <a href="https://github.com/presidentbeef/brakeman/issues/659">Bundler</a>, <a href="https://github.com/presidentbeef/brakeman/issues/709">version conflicts</a>, <a href="https://github.com/presidentbeef/brakeman/issues/767#issuecomment-180964293">RubyGem bugs</a>, and trying to maintain compatibility with older versions of Ruby <a href="https://github.com/presidentbeef/brakeman/pull/602#issuecomment-69494355">while libraries did not</a>.</p>

<p>Brakeman is most often used as an <em>application</em>, not a library. Yet most Rubyists are used to including <em>all</em> dependencies in a <code>Gemfile</code> for use with Bundler.
Doing so causes Brakeman&#8217;s dependencies to be mixed in with users&#8217; application dependencies, which doesn&#8217;t make sense and causes a lot of anguish.</p>

<p>I liken it to having to worry about whether or not your Rails application&#8217;s dependencies conflict with your browser&#8217;s. It shouldn&#8217;t matter.</p>

<p>However, Bundler does not have a way to isolate dependencies for applications like Brakeman, and Bundler is the best way to manage dependencies so we are stuck with it.</p>

<p>Since Brakeman is not normally loaded into users&#8217; applications (and I recommend against doing so), its dependencies are separate and should not really matter to the end user.
To this end, I wanted to distribute Brakeman with all its dependencies already inside the gem.</p>

<h3>Bundling Dependencies</h3>

<p>Conveniently, Bundler already has a way to do this: <code>bundle install --standalone</code>.
This generates a <code>bundle</code> directory with two subdirectories <code>bundler</code> and <code>ruby</code>.</p>

<p>The <code>bundler</code> directory just has one file: <code>setup.rb</code>. This file adds the bundled gems to the load path. We&#8217;ll come back to this file later.</p>

<p>The <code>ruby</code> directory has everything you need to run Bundler, along with all of the bundled gems and their executables.
The path to the gems looks something like <code>ruby/2.3.0/gems/rake-10.1.1/</code>.
Note this includes the Ruby version and the gem&#8217;s version.
When <code>setup.rb</code> sets up the library paths, it chooses dynamically based on the running Ruby implementation and version (which is not what we want, see below).</p>

<h3>Adding Dependencies</h3>

<p>All the dependencies are now there in the <code>bundle/</code> directory, but it&#8217;s still assumed you will be using Bundler.
I would prefer to just load the dependencies myself.</p>

<p>To do so, the Brakeman build script removes the <code>bundle/bundler/setup.rb</code> file and generates its own <code>load.rb</code> using similar logic.
However, it does not build paths dependent on the running Ruby version because we don&#8217;t know what the end user will be using.
Instead, it just globs the paths as they are and loads those.</p>

<p>In Brakeman itself, it loads <code>bundle/load.rb</code> <a href="https://github.com/presidentbeef/brakeman/blob/fb4f9de160fd97a2b72d5e01c16058718941ec3d/lib/brakeman.rb#L431-L439">lazily</a> if the file exists. I do not use it in normal testing or development.
In general, all that is needed is to <code>require</code> the <code>load.rb</code> file inside your code somewhere.</p>

<h3>Building the Gem</h3>

<p>All that is left to do is add the bundled gems to the Brakeman gem itself.</p>

<p>Note that Brakeman&#8217;s Gemfile relies on its gemspec, but the gemspec needs to rely on the bundled gems, leading to a circular dependency.</p>

<p>This simple code is all that is required in the gemspec:</p>

<pre><code>if File.exist? 'bundle/load.rb'
  s.files += Dir['bundle/ruby/*/gems/**/*'] + ['bundle/load.rb']
else
  # add dependencies as normal
end
</code></pre>

<h3>Pros</h3>

<p>The main advantage of this approach is not polluting application dependencies!
No more version conflicts! No more worries that weird Bundler or gem bugs will break users&#8217; installs.</p>

<p>In theory it also makes it easier to distribute Brakeman as a standalone application, if someone were interested in that.</p>

<h3>Cons</h3>

<p>The main problem, of course, is that this hides the dependencies.
If you add Brakeman as a dependency and then either load it programmatically or run it with Rake, you may get mysterious library conflicts.
To avoid this, use the &#8221;<a href="https://rubygems.org/gems/brakeman-lib">brakeman-lib</a>&#8221; gem, which is the same as the main Brakeman gem but does not bundle dependencies.</p>

<p>It also locks dependencies to a specific version such that updating dependencies requires a new release.
This can be good (avoid breaking with new versions) but it can also be bad if a library has a bug or vulnerability.</p>

<h3>Code</h3>

<p>The script I use to build the main Brakeman gem is <a href="https://github.com/presidentbeef/brakeman/blob/fb4f9de160fd97a2b72d5e01c16058718941ec3d/build.rb">here</a>.</p>

<p>Here&#8217;s the annotated version:</p>

<pre><code>#!/usr/bin/env ruby
puts 'Packaging Brakeman gem...'

# Clean up any existing build artifacts
system 'rm -rf bundle Gemfile.lock brakeman-*.gem' and

# Generate gem bundle in ./bundle
system 'BM_PACKAGE=true bundle install --standalone'

abort "No bundle installed" unless Dir.exist? 'bundle'

# Remove the setup.rb file we don't use
File.delete "bundle/bundler/setup.rb"
Dir.delete "bundle/bundler"

# Generate new file to set load paths
# Code below is a little confusing because it is generating code
File.open "bundle/load.rb", "w" do |f|

  # Set path at runtime
  f.puts "path = File.expand_path('../..', __FILE__)"

  # Add each gem's lib/ directory to the load path (again at runtime)
  Dir["bundle/ruby/**/lib"].each do |dir|
    f.puts %Q[$:.unshift "\#{path}/#{dir}"]
  end
end

# Build the gem
system "BM_PACKAGE=true gem build brakeman.gemspec"
</code></pre>

<p>When bundling gems and building the gem, the script sets the <code>BM_PACKAGE</code> variable so that development dependencies <a href="https://github.com/presidentbeef/brakeman/blob/fb4f9de160fd97a2b72d5e01c16058718941ec3d/brakeman.gemspec#L22">are not included</a> in the bundled gems.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Automatically Lock Old Closed GitHub Issues]]></title>
    <link href="http://presidentbeef.github.com/blog/2016/06/12/automatically-lock-old-closed-github-issues/"/>
    <updated>2016-06-12T22:27:00-07:00</updated>
    <id>http://presidentbeef.github.com/blog/2016/06/12/automatically-lock-old-closed-github-issues</id>
    <content type="html"><![CDATA[<p>I am not sure this is a problem everyone has, but I grew tired of people commenting on old, resolved GitHub issues.
Almost every time someone would comment &#8220;I have this problem, too&#8221; it would actually be a different issue. Then I&#8217;d
go through the routine of asking them to open a new issue with details about their specific problem.
Sometimes they would, and sometimes they&#8217;d never come back.</p>

<p>Fortunately, right around the time I decided I should do something about this annoyance, <a href="https://developer.github.com/changes/2016-02-11-issue-locking-api/">GitHub released an API</a>
to lock issues. (<a href="https://github.com/blog/1847-locking-conversations">Locking issues or pull requests</a> prevents any new comments except from repo collaborators.)</p>

<p>So I put together a little gem called <a href="https://github.com/presidentbeef/github-auto-locker">github-auto-locker</a> to fetch and lock old, closed issues.</p>

<p>To install it (requires Ruby):</p>

<pre><code>gem install github-auto-locker
</code></pre>

<p>Then run:</p>

<pre><code>github-auto-locker USER REPO TOKEN [age in days]
</code></pre>

<p>For example, I run this to lock resolved issues over 60 days old:</p>

<pre><code>github-auto-locker presidentbeef brakeman N0TM1R34L70K3N 60
</code></pre>

<p>The default is 120 days.</p>

<p>I&#8217;ve been running it periodically myself since February without any complaints.
Perhaps it will be useful to you!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Simple Readers-Writer Lock Gem]]></title>
    <link href="http://presidentbeef.github.com/blog/2014/02/28/simple-readers-writer-lock-gem/"/>
    <updated>2014-02-28T08:53:00-08:00</updated>
    <id>http://presidentbeef.github.com/blog/2014/02/28/simple-readers-writer-lock-gem</id>
    <content type="html"><![CDATA[<p>A <a href="http://en.wikipedia.org/wiki/Readers%E2%80%93writer_lock">readers-writer lock</a> can be used to allow many concurrent read-only operations on a resource but ensure exclusive access for modifying operations performed by &#8220;writers&#8221;. For my purposes, I needed a readers-writer lock at the thread level, basically to control access to a shared array. In my scenario, the array is accessed through a server which may server many clients at once. Some requests will be to read elements from the array, while other requests might be adding elements to the array. There is no reason to restrict reads to one client at a time, but elements need to be added while no other client is reading or writing to the array.</p>

<p><a href="https://github.com/presidentbeef/rwlock">My implementation</a> is very simple (the entire <code>RWLock</code> class is 25 lines of code) because it relies on Ruby&#8217;s <a href="http://rdoc.info/stdlib/thread/SizedQueue">SizedQueue</a> class. <code>SizedQueue</code> provides a thread-safe queue with a maximum size. If a thread attempts to add elements to a queue that is full, it will be blocked until an element is removed from the queue to make room. This is a key piece of funtionality used for the readers-writer lock implementation.</p>

<p>The <code>RWLock</code> class only really needs to provide two methods: one to provide read access, and one to provide write access. Since this is Ruby, the methods will take a block to execute the reading/writing code:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="k">class</span> <span class="nc">RWLock</span>
</span><span class='line'>  <span class="k">def</span> <span class="nf">read_sync</span>
</span><span class='line'>    <span class="c1">#lock magic</span>
</span><span class='line'>    <span class="k">yield</span>
</span><span class='line'>    <span class="c1">#lock magic</span>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">def</span> <span class="nf">write_sync</span>
</span><span class='line'>    <span class="c1">#lock magic</span>
</span><span class='line'>    <span class="k">yield</span>
</span><span class='line'>    <span class="c1">#lock magic</span>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure>


<p>The internal state of the lock will be a <code>SizedQueue</code> and a <code>Mutex</code>.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'>  <span class="k">def</span> <span class="nf">initialize</span> <span class="n">max_size</span> <span class="o">=</span> <span class="mi">10</span>
</span><span class='line'>    <span class="vi">@write_lock</span> <span class="o">=</span> <span class="no">Mutex</span><span class="o">.</span><span class="n">new</span>
</span><span class='line'>    <span class="vi">@q</span> <span class="o">=</span> <span class="no">SizedQueue</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="n">max_size</span><span class="p">)</span>
</span><span class='line'>  <span class="k">end</span>
</span></code></pre></td></tr></table></div></figure>


<p>The <code>SizedQueue</code> will essentially be used as a counting semaphore. Each time a reader enters <code>read_sync</code>, the lock will push an element onto the queue. What the element actually is doesn&#8217;t matter, but I used <code>true</code> because it&#8217;s cheap. If the queue is full, the reader will block until a space has opened up.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'>  <span class="k">def</span> <span class="nf">read_sync</span>
</span><span class='line'>    <span class="vi">@q</span><span class="o">.</span><span class="n">push</span> <span class="kp">true</span>
</span><span class='line'>    <span class="k">yield</span>
</span><span class='line'>  <span class="k">ensure</span>
</span><span class='line'>    <span class="vi">@q</span><span class="o">.</span><span class="n">pop</span>
</span><span class='line'>  <span class="k">end</span>
</span></code></pre></td></tr></table></div></figure>


<p>When a writer calls <code>write_sync</code>, it synchronizes on the mutex to prevent multiple concurrent writers. Then it adds <em>n</em> elements to the queue, where <em>n</em> is equal to the maximum size of the queue.</p>

<p>This has two effects: first, the writer is forced to wait for all current readers to finish. Second, it essentially prevents any new readers from gaining access (there is a small chance one will sneak in, but the writer will still have to wait for it).</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'>  <span class="k">def</span> <span class="nf">write_sync</span>
</span><span class='line'>    <span class="vi">@write_lock</span><span class="o">.</span><span class="n">synchronize</span> <span class="k">do</span>
</span><span class='line'>      <span class="vi">@q</span><span class="o">.</span><span class="n">max</span><span class="o">.</span><span class="n">times</span> <span class="p">{</span> <span class="vi">@q</span><span class="o">.</span><span class="n">push</span> <span class="kp">true</span> <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>      <span class="k">begin</span>
</span><span class='line'>        <span class="k">yield</span>
</span><span class='line'>      <span class="k">ensure</span>
</span><span class='line'>        <span class="vi">@q</span><span class="o">.</span><span class="n">clear</span>
</span><span class='line'>      <span class="k">end</span>
</span><span class='line'>    <span class="k">end</span>
</span><span class='line'>  <span class="k">end</span>
</span></code></pre></td></tr></table></div></figure>


<p>Once the writer is finished, the queue is cleared, allowing all waiting readers to jump in. It is most likely waiting readers will get in before waiting writers, since the write mutex is held while the queue is emptied, but no effort is made to guarantee that one way or another. In practice, though, this seems to balance well between readers and writers.</p>

<p>One obvious downside of this overall approach is the <code>SizedQueue</code> limits the number of concurrent readers. A larger queue will cause writers to wait longer (assuming many readers) while a smaller queue may cause readers to wait on other readers. The upside is readers cannot monopolize the resource and cause writer starvation.</p>

<p>Unfortunately, <code>SizedQueue#clear</code> has been broken forever, since it was simply inherited from <code>Queue</code> and didn&#8217;t actually notify waiting threads that the queue is empty. For some reason, this does not appear to matter in Ruby 1.8, but in Ruby 1.9 and 2.0 it caused a deadlock.</p>

<p>This has been fixed in Ruby 1.9.3p545 and 2.1.1. For broken versions, the <code>RWLock</code> gem monkey-patches <code>SizedQueue</code> to fix the behavior. Unfortunately, Ruby 2.0 also had a bug in <code>SizedQueue#push</code>, so it is completely incompatible. The code does work under JRuby, but there are faster implementations using Java primitives.</p>

<p>RWLock is available as <a href="https://rubygems.org/gems/rwlock">a gem</a> and of course the <a href="https://github.com/presidentbeef/rwlock">code is on GitHub</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Testing Brakeman Against 253 Rails Apps]]></title>
    <link href="http://presidentbeef.github.com/blog/2013/11/01/testing-brakeman/"/>
    <updated>2013-11-01T07:54:00-07:00</updated>
    <id>http://presidentbeef.github.com/blog/2013/11/01/testing-brakeman</id>
    <content type="html"><![CDATA[<p>Here is some information about how <a href="http://brakemanscanner.org/">Brakeman</a> is tested!</p>

<h3>Basic Testing and Continuous Integration</h3>

<p>Brakeman does have a few unit tests&#8230;pitifully few. In fact, Brakeman had no tests at all until version <a href="https://github.com/presidentbeef/brakeman/blob/master/CHANGES#L490">0.5.2</a>, nearly a year after Brakeman&#8217;s initial public release. Unit testing Brakeman remains difficult, since much of the code relies on data built up from scanning an entire Rails application.</p>

<p>As such, the majority of tests in Brakeman rely on scanning <a href="https://github.com/presidentbeef/brakeman/tree/master/test/apps">sample applications</a> and checking the resulting reports for an expected set of warnings. There are tests for the presence and absence of specific warnings, as well as checking for the specific number of warnings and an absence of reported errors. Since writing tests is pretty tedious, there is <a href="https://github.com/presidentbeef/brakeman/blob/master/test/to_test.rb">a script</a> which generates the Ruby code to asserts the presence of reported warnings. This script takes the same arguments as Brakeman, so it&#8217;s simple to generate a set of tests for a specific scenario.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="k">def</span> <span class="nf">test_information_disclosure_local_request_config</span>
</span><span class='line'>  <span class="n">assert_warning</span> <span class="ss">:type</span> <span class="o">=&gt;</span> <span class="ss">:warning</span><span class="p">,</span>
</span><span class='line'>    <span class="ss">:warning_code</span> <span class="o">=&gt;</span> <span class="mi">61</span><span class="p">,</span>
</span><span class='line'>    <span class="ss">:fingerprint</span> <span class="o">=&gt;</span> <span class="s2">&quot;081f5d87a244b41d3cf1d5994cb792d2cec639cd70e4e306ffe1eb8abf0f32f7&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="ss">:warning_type</span> <span class="o">=&gt;</span> <span class="s2">&quot;Information Disclosure&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="ss">:message</span> <span class="o">=&gt;</span> <span class="sr">/^Detailed\ exceptions\ are\ enabled\ in\ produ/</span><span class="p">,</span>
</span><span class='line'>    <span class="ss">:confidence</span> <span class="o">=&gt;</span> <span class="mi">0</span><span class="p">,</span>
</span><span class='line'>    <span class="ss">:relative_path</span> <span class="o">=&gt;</span> <span class="s2">&quot;config/environments/production.rb&quot;</span>
</span><span class='line'><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure>


<p>The tests run on <a href="https://travis-ci.org/presidentbeef/brakeman">Travis CI</a> which is integrated with GitHub. This is especially helpful for testing compatibility with Ruby 1.8.7, which many Rails applications still run on and Brakeman will probably continue supporting for a long time.</p>

<h3>Regression Testing with a Wide Net</h3>

<p>Unfortunately, the sample applications Brakeman uses for tests are quite limited, not real, and generally just test very specific warnings or previous bugs. To gain higher confidence that Brakeman is not too broken, Brakeman is run against a set of 253 open source Rails applications I have managed to scrape together. (If you have an open source application to add to this test set, please let me know!)</p>

<p>The scans are run on my personal machine - six jobs in parallel, which takes about nine minutes total. After puttering around with a few different approaches, I ended up simply using the <a href="http://rdoc.info/stdlib/thread/Queue">Queue</a> class from Ruby&#8217;s standard library as the job queue. In a Frankenstein combination, a shell script starts up a JRuby process, which builds the Brakeman gem and then runs six threads for scan jobs. Each job launches Brakeman as an external process running under MRI 1.9.3 and, if successful, produces a JSON report. The JSON report is then augmented with some information about the Brakeman commit and the app that was scanned.</p>

<p>When all the apps have been scanned, the JSON reports are tarred up and sent to a server. I use <a href="https://www.digitalocean.com/?refcode=35d9e7aec070">DigitalOcean</a> (referral link!) because I needed an Ubuntu setup and their API lets me use some handy <a href="https://github.com/presidentbeef/my_ocean">scripts</a> to spin the server up and down whenever I need it (and only pay for when it&#8217;s up).</p>

<p>On the server, the reports are unpacked and imported into a <a href="http://rethinkdb.com/">RethinkDB</a> database. Since RethinkDB stores JSON documents, it&#8217;s simple to dump the JSON reports from Brakeman in there. I just have two tables: one just contains commit SHAs and their timestamps, and the other contains the actual reports. I have secondary indexes on the reports to efficiently look them up by the name of the Rails app or the Brakeman SHA.</p>

<p>A small <a href="http://www.sinatrarb.com/">Sinatra</a> app serves up some basic graphs and allows two commits to be compared:</p>

<p><img src="http://presidentbeef.github.com/images/blog/brakeman-graphs.png" title="Ugly, I know" alt="Brakeman Graphs" /></p>

<p>This &#8220;system&#8221; is not open source at the moment, but probably will be in the future when I&#8217;ve removed hard-coded stuff.</p>

<p>Anyhow, since I have all these reports, I can share some data&#8230;but just be forewarned you can&#8217;t really draw any conclusions from it!</p>

<h3>Numbers!</h3>

<p>This is the RethinkDB query for warnings per category, in JavaScript since I ran it in the web UI:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">r</span><span class="p">.</span><span class="nx">db</span><span class="p">(</span><span class="s2">&quot;brakeman&quot;</span><span class="p">).</span>
</span><span class='line'>  <span class="nx">table</span><span class="p">(</span><span class="s2">&quot;reports&quot;</span><span class="p">).</span>
</span><span class='line'>  <span class="nx">getAll</span><span class="p">(</span><span class="s2">&quot;25a41dfcd9171695e731533c50de573c71c63deb&quot;</span><span class="p">,</span> <span class="p">{</span><span class="nx">index</span><span class="o">:</span> <span class="s2">&quot;brakeman_sha&quot;</span><span class="p">}).</span>
</span><span class='line'>  <span class="nx">concatMap</span><span class="p">(</span><span class="kd">function</span><span class="p">(</span><span class="nx">rep</span><span class="p">)</span> <span class="p">{</span> <span class="k">return</span> <span class="nx">rep</span><span class="p">(</span><span class="s2">&quot;brakeman_report&quot;</span><span class="p">)(</span><span class="s2">&quot;warnings&quot;</span><span class="p">)</span> <span class="p">}).</span>
</span><span class='line'>  <span class="nx">groupBy</span><span class="p">(</span><span class="s2">&quot;warning_type&quot;</span><span class="p">,</span> <span class="nx">r</span><span class="p">.</span><span class="nx">count</span><span class="p">).</span>
</span><span class='line'>  <span class="nx">orderBy</span><span class="p">(</span><span class="nx">r</span><span class="p">.</span><span class="nx">desc</span><span class="p">(</span><span class="s2">&quot;reduction&quot;</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>




<table>
  <tr>
    <th>
      <strong>Warning Category</strong>
    </th>
    <th>
      <strong>Count</strong>
    </th>
  </tr>
  <tr>
    <td>
      Cross Site Scripting
    </td>
    <td>
      6669
    </td>
  </tr>
  <tr>
    <td>
      Mass Assignment
    </td>
    <td>
      3385
    </td>
  </tr>
  <tr>
    <td>
      SQL Injection
    </td>
    <td>
      1353
    </td>
  </tr>
  <tr>
    <td>
      Remote Code Execution
    </td>
    <td>
      458
    </td>
  </tr>
  <tr>
    <td>
      Denial of Service
    </td>
    <td>
      440
    </td>
  </tr>
  <tr>
    <td>
      Redirect
    </td>
    <td>
      232
    </td>
  </tr>
  <tr>
    <td>
      Format Validation
    </td>
    <td>
      230
    </td>
  </tr>
  <tr>
    <td>
      Attribute Restriction
    </td>
    <td>
      205
    </td>
  </tr>
  <tr>
    <td>
      File Access
    </td>
    <td>
      200
    </td>
  </tr>
  <tr>
    <td>
      Session Setting
    </td>
    <td>
      169
    </td>
  </tr>
  <tr>
    <td>
      Dynamic Render Path
    </td>
    <td>
      140
    </td>
  </tr>
  <tr>
    <td>
      Command Injection
    </td>
    <td>
      116
    </td>
  </tr>
  <tr>
    <td>
      Cross-Site Request Forgery
    </td>
    <td>
      96
    </td>
  </tr>
  <tr>
    <td>
      Default Routes
    </td>
    <td>
      67
    </td>
  </tr>
  <tr>
    <td>
      Response Splitting
    </td>
    <td>
      44
    </td>
  </tr>
  <tr>
    <td>
      Dangerous Eval
    </td>
    <td>
      43
    </td>
  </tr>
  <tr>
    <td>
      Dangerous Send
    </td>
    <td>
      33
    </td>
  </tr>
  <tr>
    <td>
      Nested Attributes
    </td>
    <td>
      5
    </td>
  </tr>
  <tr>
    <td>
      Information Disclosure
    </td>
    <td>
      2
    </td>
  </tr>
  <tr>
    <td>
      Authentication
    </td>
    <td>
      2
    </td>
  </tr>
</table>


<br>


<p>Some educated guesses about these numbers:</p>

<ul>
<li>Mass assignment numbers are likely high because they include warnings about dangerous attributes that are whitelisted.</li>
<li>Remote code injection is mostly uses of <code>constantize</code> and similar methods.</li>
<li>Most denial of service warnings are calls to <code>to_sym</code> on parameters</li>
<li>Response splitting is interesting because it is only reported in regards to <a href="https://groups.google.com/d/msg/rubyonrails-security/b_yTveAph2g/jKe6OuRC47sJ">CVE-2011-3186</a> which was fixed in Rails 2.3.13.</li>
</ul>


<p>This last point made me curious about the Rails versions in use by the applications. Keeping in mind these apps are not necessarily up-to-date, they represent at least 37 different versions! Some were reported as unknown versions.</p>

<p>Here are the top ten:</p>

<table>
  <tr>
    <th>
      <strong>Rails Version</strong>
    </th>
    <th>
      <strong>Count</strong>
    </th>
  </tr>
  <tr>
    <td>
      3.2.13
    </td>
    <td>
      26
    </td>
  </tr>
  <tr>
    <td>
      2.3.5
    </td>
    <td>
      19
    </td>
  </tr>
  <tr>
    <td>
      3.0.3
    </td>
    <td>
      18
    </td>
  </tr>
  <tr>
    <td>
      3.2.14
    </td>
    <td>
      14
    </td>
  </tr>
  <tr>
    <td>
      4.0.0
    </td>
    <td>
      11
    </td>
  </tr>
  <tr>
    <td>
      3.2.12
    </td>
    <td>
      9
    </td>
  </tr>
  <tr>
    <td>
      2.3.8
    </td>
    <td>
      8
    </td>
  </tr>
  <tr>
    <td>
      3.2.11
    </td>
    <td>
      8
    </td>
  </tr>
  <tr>
    <td>
      3.0.0
    </td>
    <td>
      7
    </td>
  </tr>
  <tr>
    <td>
      3.1.0
    </td>
    <td>
      6
    </td>
  </tr>
</table>


<br>


<p>With so many applications and nearly 14,000 warnings, there is a lot more information to go through here.</p>

<p>For now this process is used to help test new Brakeman code and avoid regressions. It&#8217;s stopped quite a few bugs from going out!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Fast Compact Sparse Bit Sets]]></title>
    <link href="http://presidentbeef.github.com/blog/2013/09/02/fast-compact-sparse-bitsets/"/>
    <updated>2013-09-02T14:49:00-07:00</updated>
    <id>http://presidentbeef.github.com/blog/2013/09/02/fast-compact-sparse-bitsets</id>
    <content type="html"><![CDATA[<p>Imagine you need a relatively compact data structure for quickly checking membership of mostly-consecutive non-negative integers. (If this sounds really specific, it is because it is precisely what I needed for a particular project.)</p>

<p>The Ruby standard library contains a <a href="http://rdoc.info/stdlib/set/1.9.3/Set">Set</a> class which may be a good starting point. Set is actually implemented as a Hash with the Set elements as keys and <code>true</code> as the values. Thus the overhead for storing a value in the Set is essentially only the value itself since all keys point to the same <code>true</code> object. Assuming a 64-bit machine, the overhead will be 64 bits per value. This seems reasonable, but given the specific limitations of the values we wish to store, perhaps we can do better?</p>

<h3>Bit Sets</h3>

<p>A bit set is a compact data structure of binary values where membership is indicated by setting a bit to 1. The position of the bit indicates the element value. For example, the second bit from the right might be used to indicate whether or not the value 1 is in the set.</p>

<p>One method to determine membership is to AND the bit set with a mask with only the desired bit set to 1. If the result is 0, the value is not in the set. If it is any other result (actually the mask itself, but the zero check is sufficinet), the value is a member of the set.</p>

<p>In Ruby, this looks like</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="n">bitset</span> <span class="o">&amp;</span> <span class="p">(</span><span class="mi">1</span> <span class="o">&lt;&lt;</span> <span class="n">num</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span>
</span></code></pre></td></tr></table></div></figure>


<p>For example, to check if the value 4 is in the set, we use the mask <code>00010000</code> (the 5th bit from the right is set to 1) which is the decimal value <code>8</code>:</p>

<p><img src="http://presidentbeef.github.com/images/blog/bitset-example1.png" alt="Bit Set Checking Example 1" /></p>

<p>Since the result is zero, we know the value 4 is not in the set.</p>

<p>If we check for the value <code>6</code>, the result is not zero, indicating the value is a member of the set:</p>

<p><img src="http://presidentbeef.github.com/images/blog/bitset-example2.png" alt="Bit Set Checking Example 2" /></p>

<p>Now, instead of 64 bits per value, it only requires a single bit! Now we just need to put a lot of bits together, either by using a long string or a bunch of integers in an array.</p>

<h3>Sparse Bit Sets</h3>

<p>The problem with a long binary string or an array of integers is that membership is entirely position-based. To store the value <code>1000</code>, the data structure requires 1001 bits, all but one of which is set to 0. This is quite inefficient, especially for very large values.</p>

<p>One solution is to create a sparse bit set by combining a hash table with bit sets as values. The hash table keys provide fast look up of the correct bit set, then the bit set is checked for the desired element. The keys indicate the lowest value stored in the bit set (e.g., the decimal key <code>4</code> pointing to the binary bit set <code>00000001</code> would mean the value <code>4</code> is in the set).</p>

<p>Below is an example of a hash table using integer keys and 8 bit integers for the bit sets:</p>

<p><img src="http://presidentbeef.github.com/images/blog/sparse-bitset-example.png" alt="Sparse Bit Set Example" /></p>

<p>The average overhead is <code>⌊(m * n) / w⌋ + m</code> bits, where <em>m</em> is the number of values (assumed to be consecutive), <em>w</em> is the number of bits per bit set, and <em>n</em> is the number of bits per key. In 64-bit Ruby, if we use integers for the bit sets, <em>n</em> = 64 and <em>w</em> = 62<a href="#footnote">*</a>. This works out to an average of 2 bits per value in the set. Of course, a single value incurs the overhead of both the key and the bit set: 128 bits! But if there are many consecutive values, the cost per value begins to shrink. For example, the numbers 0 to 61 can be stored in a single bit set, so 62 values can be stored in the 128 bits and we are back to about 2 bits per value.</p>

<p>Note that while it is best to use consecutive values which fit neatly into the bit sets (in this case, runs of 62 integers), the sequences can start and end at arbitrary points with only a little &#8220;wasted&#8221; overhead. To store just the number <code>1000</code>, we now only need 128 bits, not 1001.</p>

<p>On top of the space savings, the membership checks remain fast. Still assuming 64-bit Ruby, to determine if a value is in the table look up index <code>i = value / 61</code>. Then check the bit set with <code>bitset &amp; (1 &lt;&lt; (value % 61) != 0</code> as previously. (The divisor is 61 because there are 62 bits, but the values are 0 to 61).</p>

<h3>Space Efficiency</h3>

<p>I have implemented a Ruby version of the data structure described above which I call the <a href="https://github.com/presidentbeef/dumb-numb-set">Dumb Numb Set</a> (DNS).</p>

<p>To measure the space used by the bit sets, we compare the Marshal data size for the bit sets versus regular Hashes (using <code>true</code> for all values, just like a Ruby Set).</p>

<p>These are the results for perfectly ordered data on a 64-bit version of Ruby 1.9.3 (size is number of bytes):</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="no">Items</span>        <span class="no">Hash</span>         <span class="no">DNS</span>      <span class="o">%</span><span class="n">reduction</span>
</span><span class='line'><span class="o">---------------------------------------------</span>
</span><span class='line'>   <span class="mi">1</span>   <span class="o">|</span>           <span class="mi">7</span>  <span class="o">|</span>        <span class="mi">41</span>   <span class="o">|-</span><span class="mi">486</span><span class="o">%</span>
</span><span class='line'> <span class="mi">100</span>   <span class="o">|</span>         <span class="mi">307</span>  <span class="o">|</span>        <span class="mi">61</span>   <span class="o">|</span>  <span class="mi">80</span><span class="o">%</span>
</span><span class='line'>  <span class="mi">1</span><span class="n">k</span>   <span class="o">|</span>        <span class="mi">4632</span>  <span class="o">|</span>       <span class="mi">253</span>   <span class="o">|</span>  <span class="mi">95</span><span class="o">%</span>
</span><span class='line'> <span class="mi">10</span><span class="n">k</span>   <span class="o">|</span>       <span class="mi">49632</span>  <span class="o">|</span>      <span class="mi">2211</span>   <span class="o">|</span>  <span class="mi">96</span><span class="o">%</span>
</span><span class='line'><span class="mi">100</span><span class="n">k</span>   <span class="o">|</span>      <span class="mi">534098</span>  <span class="o">|</span>     <span class="mi">24254</span>   <span class="o">|</span>  <span class="mi">95</span><span class="o">%</span>
</span><span class='line'>  <span class="mi">1</span><span class="n">M</span>   <span class="o">|</span>     <span class="mi">5934098</span>  <span class="o">|</span>    <span class="mi">245565</span>   <span class="o">|</span>  <span class="mi">96</span><span class="o">%</span>
</span><span class='line'> <span class="mi">10</span><span class="n">M</span>   <span class="o">|</span>    <span class="mi">59934098</span>  <span class="o">|</span>   <span class="mi">2557080</span>   <span class="o">|</span>  <span class="mi">96</span><span class="o">%</span>
</span><span class='line'><span class="mi">100</span><span class="n">M</span>   <span class="o">|</span>   <span class="mi">683156884</span>  <span class="o">|</span>  <span class="mi">26163639</span>   <span class="o">|</span>  <span class="mi">96</span><span class="o">%</span>
</span><span class='line'>  <span class="mi">1</span><span class="n">B</span>   <span class="o">|</span>         <span class="p">?</span>    <span class="o">|</span> <span class="mi">262229211</span>   <span class="o">|</span>   <span class="p">?</span>
</span><span class='line'><span class="o">---------------------------------------------</span>
</span></code></pre></td></tr></table></div></figure>


<p>At 1 billion items, my machine ran out of memory.</p>

<p>For a single item, as expected, overhead in the DNS is quite high. But for as little as 100 items in the set, the DNS is considerably more compact.</p>

<p>This is, however, the best case scenario for the DNS. Less perfectly dense values cause it to <a href="https://github.com/presidentbeef/dumb-numb-set#less-dense-data">be less efficient</a>. For <em>very</em> sparse values, a Hash/Set is probably a better choice.</p>

<h3>Even Better Space Efficiency</h3>

<p>It may not surprise you to find out I was very interested in minimizing the serialized version of the sparse bit set for sending it over a network. In investigating easy but compact ways of doing so, I realized the Marshal data for Hashes and integers is not very compact, especially for large integers.</p>

<p>Fortunately, there is an existing solution for this scenario called <a href="http://msgpack.org/">MessagePack</a>. For storing 1 million values, serialized size is reduced from 245,565 to 196,378 bytes (20%). The DNS will use MessagePack automatically if it is installed.</p>

<h3>Performance</h3>

<p>Somewhat surprisingly, the DNS is quite fast even when compared to MRI Ruby&#8217;s Hash implementation.</p>

<p>With MRI Ruby 1.9.3p448 (x86_64) and 1 million values:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'>                           <span class="n">user</span>     <span class="nb">system</span>      <span class="n">total</span>        <span class="n">real</span>
</span><span class='line'><span class="no">Hash</span> <span class="n">add</span> <span class="n">random</span>            <span class="mi">0</span><span class="o">.</span><span class="mi">540000</span>   <span class="mi">0</span><span class="o">.</span><span class="mo">020000</span>   <span class="mi">0</span><span class="o">.</span><span class="mi">560000</span> <span class="p">(</span>  <span class="mi">0</span><span class="o">.</span><span class="mi">549499</span><span class="p">)</span>
</span><span class='line'><span class="no">DumbNumbSet</span> <span class="n">add</span> <span class="n">random</span>     <span class="mi">0</span><span class="o">.</span><span class="mi">850000</span>   <span class="mi">0</span><span class="o">.</span><span class="mo">020000</span>   <span class="mi">0</span><span class="o">.</span><span class="mi">870000</span> <span class="p">(</span>  <span class="mi">0</span><span class="o">.</span><span class="mi">864700</span><span class="p">)</span>
</span><span class='line'><span class="no">Hash</span> <span class="n">add</span> <span class="k">in</span> <span class="n">order</span>          <span class="mi">0</span><span class="o">.</span><span class="mi">540000</span>   <span class="mi">0</span><span class="o">.</span><span class="mo">020000</span>   <span class="mi">0</span><span class="o">.</span><span class="mi">560000</span> <span class="p">(</span>  <span class="mi">0</span><span class="o">.</span><span class="mi">556441</span><span class="p">)</span>
</span><span class='line'><span class="no">DumbNumbSet</span> <span class="n">add</span> <span class="k">in</span> <span class="n">order</span>   <span class="mi">0</span><span class="o">.</span><span class="mi">490000</span>   <span class="mi">0</span><span class="o">.</span><span class="mo">000000</span>   <span class="mi">0</span><span class="o">.</span><span class="mi">490000</span> <span class="p">(</span>  <span class="mi">0</span><span class="o">.</span><span class="mi">483713</span><span class="p">)</span>
</span><span class='line'><span class="no">Hash</span> <span class="n">add</span> <span class="n">shuffled</span>          <span class="mi">0</span><span class="o">.</span><span class="mi">570000</span>   <span class="mi">0</span><span class="o">.</span><span class="mo">020000</span>   <span class="mi">0</span><span class="o">.</span><span class="mi">590000</span> <span class="p">(</span>  <span class="mi">0</span><span class="o">.</span><span class="mi">589316</span><span class="p">)</span>
</span><span class='line'><span class="no">DumbNumbSet</span> <span class="n">add</span> <span class="n">shuffled</span>   <span class="mi">0</span><span class="o">.</span><span class="mi">540000</span>   <span class="mi">0</span><span class="o">.</span><span class="mo">010000</span>   <span class="mi">0</span><span class="o">.</span><span class="mi">550000</span> <span class="p">(</span>  <span class="mi">0</span><span class="o">.</span><span class="mi">538420</span><span class="p">)</span>
</span><span class='line'><span class="no">Hash</span> <span class="n">look</span> <span class="n">up</span>               <span class="mi">0</span><span class="o">.</span><span class="mi">930000</span>   <span class="mi">0</span><span class="o">.</span><span class="mo">010000</span>   <span class="mi">0</span><span class="o">.</span><span class="mi">940000</span> <span class="p">(</span>  <span class="mi">0</span><span class="o">.</span><span class="mi">940849</span><span class="p">)</span>
</span><span class='line'><span class="no">DNS</span> <span class="n">look</span> <span class="n">up</span>                <span class="mi">0</span><span class="o">.</span><span class="mi">820000</span>   <span class="mi">0</span><span class="o">.</span><span class="mo">000000</span>   <span class="mi">0</span><span class="o">.</span><span class="mi">820000</span> <span class="p">(</span>  <span class="mi">0</span><span class="o">.</span><span class="mi">818728</span><span class="p">)</span>
</span><span class='line'><span class="no">Hash</span> <span class="n">remove</span>                <span class="mi">0</span><span class="o">.</span><span class="mi">980000</span>   <span class="mi">0</span><span class="o">.</span><span class="mo">030000</span>   <span class="mi">1</span><span class="o">.</span><span class="mo">010000</span> <span class="p">(</span>  <span class="mi">0</span><span class="o">.</span><span class="mi">999362</span><span class="p">)</span>
</span><span class='line'><span class="no">DNS</span> <span class="n">remove</span>                 <span class="mi">0</span><span class="o">.</span><span class="mi">950000</span>   <span class="mi">0</span><span class="o">.</span><span class="mo">000000</span>   <span class="mi">0</span><span class="o">.</span><span class="mi">950000</span> <span class="p">(</span>  <span class="mi">0</span><span class="o">.</span><span class="mi">953170</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>The only operation slower than a regular Hash is inserting many random values. All other operations are roughly equal.</p>

<h3>Conclusion</h3>

<p>For my specific scenario, a simple custom data structure was just as fast as a built-in data structure, but required significantly less space for the expected use case.</p>

<p>There are other solutions for this type of problem, but it should be noted I only really care about fast insertion, fast membership checks, and compact representation. Additionally, values may be very large, although I attempt to keep them within the Fixnum range for Ruby (i.e. less than 2<sup>62</sup> - 1). This rules out some implementations which require arrays the size of the maximum value!</p>

<p>I also did not want to deal with compression schemes, of which there are quite a few, since my sets were going to be dynamic. I imagine there are very efficient implementations for fixed data sets.</p>

<p><a name="footnote"></a></p>

<h4>Footnote: Integer Size in Ruby</h4>

<p>Integers in 32-bit MRI Ruby only have 30 bits available, and in 64-bit MRI Ruby they only have 62 bits available:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="err">$</span> <span class="n">irb</span>
</span><span class='line'><span class="mi">1</span><span class="o">.</span><span class="mi">9</span><span class="o">.</span><span class="mi">3</span><span class="n">p448</span> <span class="p">:</span><span class="mo">001</span> <span class="o">&gt;</span> <span class="p">(</span><span class="s2">&quot;1&quot;</span> <span class="o">*</span> <span class="mi">62</span><span class="p">)</span><span class="o">.</span><span class="n">to_i</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">class</span>
</span><span class='line'> <span class="o">=&gt;</span> <span class="no">Fixnum</span>
</span><span class='line'><span class="mi">1</span><span class="o">.</span><span class="mi">9</span><span class="o">.</span><span class="mi">3</span><span class="n">p448</span> <span class="p">:</span><span class="mo">002</span> <span class="o">&gt;</span> <span class="p">(</span><span class="s2">&quot;1&quot;</span> <span class="o">*</span> <span class="mi">63</span><span class="p">)</span><span class="o">.</span><span class="n">to_i</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">class</span>
</span><span class='line'> <span class="o">=&gt;</span> <span class="no">Bignum</span>
</span></code></pre></td></tr></table></div></figure>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Avoiding SQL Injection in Rails]]></title>
    <link href="http://presidentbeef.github.com/blog/2013/02/08/avoid-sql-injection-in-rails/"/>
    <updated>2013-02-08T09:45:00-08:00</updated>
    <id>http://presidentbeef.github.com/blog/2013/02/08/avoid-sql-injection-in-rails</id>
    <content type="html"><![CDATA[<p>SQL injection (SQLi) is any situation in which a user can manipulate a database query in an unintended manner. Consequences of SQL injection vulnerabilites range from data leaks, to authentication bypass, to root access on a database server. In short, it is a very big deal.</p>

<p>Most Rails applications interact with a database through ActiveRecord, the default and convenient Object Relational Mapping (ORM) layer which comes with Rails.
Generally, use of ORMs is safer than not. They can provide abstraction and safety and allow developers to avoid manually building SQL queries. They can embody best practices and prevent careless handling of external input.</p>

<p>Instead of unsafe code like</p>

<pre><code>query = "SELECT * FROM users WHERE name = '#{name}' AND password = '#{password'} LIMIT 1"
results = DB.execute(query)
</code></pre>

<p>You can have safer, simpler code like</p>

<pre><code>User.where(:name =&gt; name, :password =&gt; :password).first
</code></pre>

<p>My impression is many people assume the Rails framework will protect them as long as they avoid the &#8220;obviously dangerous&#8221; methods, like <code>find_by_sql</code>.</p>

<p>Unfortunately, ActiveRecord is unsafe more often than it is safe. It does provide parameterization of queries (the API documentation for which can be <a href="http://api.rubyonrails.org/classes/ActiveRecord/Base.html">found here</a>) for some methods, there are many methods for which it does not. While these methods are not intended to be used with user input, the truth is that has never stopped anyone.</p>

<p>To make it clear how dangerous it can be to use ActiveRecord, consider <a href="http://api.rubyonrails.org/classes/ActiveRecord/FinderMethods.html#method-i-exists-3F">ActiveRecord::FinderMethods#exists?</a> which queries the database and returns <code>true</code> if a matching record exists. The argument can be a primary key (either integer or string, if a string it will be sanitized), an array consisting of a template string and values to safely interpolate, or a hash of column-value pairs (which will be sanitized).</p>

<p>Here is an example of using <code>exists?</code> to determine if a given user exists:</p>

<pre><code>User.exists? params[:user_id]
</code></pre>

<p>This looks harmless, since <code>params[:user_id]</code> is a string, and strings will be sanitized. In fact, the documentation clearly points out not to pass in conditions as strings, because they will be escaped.</p>

<p>However, there is no gaurantee <code>params[:user_id]</code> is a string. An attacker could send a request with <code>?user_id[]=some_attack_string</code>, which Rails will turn into an array <code>["some_attack_string"]</code>. Now the argument is an array, the first element of which is not escaped.</p>

<p>To avoid this problem, the user input should be converted to the expected type:</p>

<pre><code>User.exists? params[:user_id].to_i
</code></pre>

<p>Or use a hash:</p>

<pre><code>User.exists? :id =&gt; params[:user_id]
</code></pre>

<p>This should be the approach for all uses of user input. Do not assume <em>anything</em> about values from external sources or what safety mechanisms a method might have.</p>

<p>While working on <a href="http://brakemanscanner.org/">Brakeman</a>, I thought it would be useful to put together a list of all the unsafe ways one can use ActiveRecord.</p>

<p>To make it easier on myself, I built the list into a Rails application so I could easily test, verify, and record any findings. The source is <a href="https://github.com/presidentbeef/inject-some-sql">available here</a> for those who would like try out the examples. The application is a single page of all the queries and example injections. From there one can submit queries and see the results:</p>

<p><img src="http://presidentbeef.github.com/images/blog/inject-some-sql.png" alt="Query Example" /></p>

<p>The resulting information is available at <a href="http://rails-sqli.org">rails-sqli.org</a>, including examples of how SQL injection can occur and the resulting queries. This is basically a big list of what <em>not</em> to do when using ActiveRecord. Again, please feel free to <a href="https://github.com/presidentbeef/inject-some-sql">contribute</a> so that the list can be as authoritative as possible and help everyone avoid SQL injection in Rails.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Faster Call Indexing in Brakeman]]></title>
    <link href="http://presidentbeef.github.com/blog/2012/11/28/faster-call-indexing-in-brakeman-1-dot-8-3/"/>
    <updated>2012-11-28T11:49:00-08:00</updated>
    <id>http://presidentbeef.github.com/blog/2012/11/28/faster-call-indexing-in-brakeman-1-dot-8-3</id>
    <content type="html"><![CDATA[<h2>Background</h2>

<p>About a month ago, an <a href="https://github.com/presidentbeef/brakeman/issues/171">issue</a> was reported where <a href="http://brakemanscanner.org">Brakeman</a> taking a ridiculously long time on the &#8220;call indexing&#8221; step. At the time, I was pessimistic about opportunities to improve the performance of call indexing, since it is a pretty simple operation.</p>

<h3>Call Indexing</h3>

<p>The majority of the checks performed by Brakeman involve finding and examining method calls (e.g., SQL queries). In order to make these checks faster, Brakeman scans an app once and then saves information about each method call in a data structure called the &#8220;call index&#8221;. This makes searching for specific method calls very fast.</p>

<p>The call index allows search for methods by name and also by the class of the target. For example, it is possible to search for all calls to <code>open</code> on <code>File</code>. It also allows searching via regular expressions for methods and targets.</p>

<h2>Investigation</h2>

<p>I happened to notice a Rails application in my collection which also seemed to take a long time indexing calls. So I ran it through <a href="https://github.com/tmm1/perftools.rb">perftools.rb</a> to see if there was anything interesting going on.</p>

<p>This is the result:</p>

<p><a href="http://presidentbeef.github.com/images/blog/brakeman-scan-1.8.2.pdf"><img src="http://presidentbeef.github.com/images/blog/brakeman-scan-1.8.2.png" alt="Brakeman 1.8.2 scan" /></a></p>

<p>The large amount of time spent in the garbage collector (60%) was high even for Brakeman. But then something else caught my eye:</p>

<p><img src="http://presidentbeef.github.com/images/blog/call-indexing-1.8.2.png" alt="Call indexing in 1.8.2" /></p>

<p>This scan spent 4.7% of its time converting <code>Sexp</code>s to strings while indexing calls. This seemed excessive.</p>

<p>This is the entirety of the call indexing code:</p>

<figure class='code'><figcaption><span>call_index.rb</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'>  <span class="k">def</span> <span class="nf">index_calls</span> <span class="n">calls</span>
</span><span class='line'>    <span class="n">calls</span><span class="o">.</span><span class="n">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">call</span><span class="o">|</span>
</span><span class='line'>      <span class="vi">@methods</span> <span class="o">&lt;&lt;</span> <span class="n">call</span><span class="o">[</span><span class="ss">:method</span><span class="o">].</span><span class="n">to_s</span>
</span><span class='line'>      <span class="vi">@targets</span> <span class="o">&lt;&lt;</span> <span class="n">call</span><span class="o">[</span><span class="ss">:target</span><span class="o">].</span><span class="n">to_s</span>
</span><span class='line'>      <span class="vi">@calls_by_method</span><span class="o">[</span><span class="n">call</span><span class="o">[</span><span class="ss">:method</span><span class="o">]]</span> <span class="o">&lt;&lt;</span> <span class="n">call</span>
</span><span class='line'>      <span class="vi">@calls_by_target</span><span class="o">[</span><span class="n">call</span><span class="o">[</span><span class="ss">:target</span><span class="o">]]</span> <span class="o">&lt;&lt;</span> <span class="n">call</span>
</span><span class='line'>    <span class="k">end</span>
</span><span class='line'>  <span class="k">end</span>
</span></code></pre></td></tr></table></div></figure>


<p><code>@methods</code> and <code>@targets</code> are sets which contain the string versions of all the methods and method targets. This is <em>exclusively</em> used to search for methods and targets via regular expressions.</p>

<p>The call method will always be a symbol&#8230;but what about the target? It turns out that while much of the time it is a symbol, if a sane value like <code>:File</code> or <code>:@something</code> cannot be found, then it will be the entire <code>Sexp</code>! This is where Brakeman was wasting time calling <code>Sexp#to_s</code>.</p>

<p>The quick fix was to only store symbol targets in the <code>@targets</code> set, ignoring any other target values.</p>

<h2>Results</h2>

<p>Scanning the same application with Brakeman 1.8.3 has this result:</p>

<p><a href="http://presidentbeef.github.com/images/blog/brakeman-scan-1.8.3.pdf"><img src="http://presidentbeef.github.com/images/blog/brakeman-scan-1.8.3.png" alt="Brakeman 1.8.3 scan" /></a></p>

<p>Garbage collection time dropped from 60% to 42%. While still very high, this is a good sign. Time spent indexing calls has dropped from 5.4% to 1.8% and the calls to <code>Sexp#to_s</code> have vanished.</p>

<p>The total scan time dropped from 3.5 minutes to about 2 minutes. For the original reporter, scan times went from <a href="https://github.com/presidentbeef/brakeman/issues/171#issuecomment-10344355">78 minutes to 40 <em>seconds</em></a>.</p>

<h2>More Improvements</h2>

<p>Looking through Brakeman, it does not currently use the &#8220;search via regex&#8221; feature for the call index. So the method and target name sets can be removed entirely.</p>

<p>Going even further, nowhere does Brakeman search for targets by any values other than symbols. Note in the graph below that <code>Array#eql?</code> was sampled 1,330 times during call indexing:</p>

<p><img src="http://presidentbeef.github.com/images/blog/call-indexing-hashing-sexp.png" alt="Call indexing hashing" /></p>

<p>Since <code>Sexp</code>s are subclassed from <code>Array</code>, it is clear that these calls are generated when using the <code>call[:target]</code> as a hash key (line 6 above). Again, the current Brakeman code only searches for call targets by symbol, never by a full <code>Sexp</code>. There is no reason to the call targets that are <code>Sexp</code>s.</p>

<p>This is the modified call indexing code:</p>

<figure class='code'><figcaption><span>Modified call_index.rb</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'>  <span class="k">def</span> <span class="nf">index_calls</span> <span class="n">calls</span>
</span><span class='line'>    <span class="n">calls</span><span class="o">.</span><span class="n">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">call</span><span class="o">|</span>
</span><span class='line'>      <span class="vi">@calls_by_method</span><span class="o">[</span><span class="n">call</span><span class="o">[</span><span class="ss">:method</span><span class="o">]]</span> <span class="o">&lt;&lt;</span> <span class="n">call</span>
</span><span class='line'>
</span><span class='line'>      <span class="k">unless</span> <span class="n">call</span><span class="o">[</span><span class="ss">:target</span><span class="o">].</span><span class="n">is_a?</span> <span class="no">Sexp</span>
</span><span class='line'>        <span class="vi">@calls_by_target</span><span class="o">[</span><span class="n">call</span><span class="o">[</span><span class="ss">:target</span><span class="o">]]</span> <span class="o">&lt;&lt;</span> <span class="n">call</span>
</span><span class='line'>      <span class="k">end</span>
</span><span class='line'>    <span class="k">end</span>
</span><span class='line'>  <span class="k">end</span>
</span></code></pre></td></tr></table></div></figure>


<p>With this code in place, call indexing does not even show up under perftools. Speed improvements vary by project, but this should at least shave off a few seconds. <a href="https://github.com/presidentbeef/brakeman/pull/189#issuecomment-10768297">YMMV</a>.</p>

<h2>Wrapping Up</h2>

<p>Some quick profiling led me to performance improvements where I really did not expect to find them. Sadly, this is one of the cleanest, simplest parts of Brakeman, so I know there are many other instances where Brakeman can be improved. Prior to the introduction of the call index in Brakeman 1.0, I was trying to keep Brakeman scans under 20 minutes (on large applications). Now I worry when scans take longer than a few minutes.</p>

<p>97% of the open source Rails applications I use as test cases can be scanned in less than 30 seconds. Unfortunately, this probably does not reflect scan times for large, commercial applications. Please <a href="https://github.com/presidentbeef/brakeman/issues">report</a> any long-running scans! It may lead to more speed improvements like the ones above.</p>
]]></content>
  </entry>
  
</feed>
